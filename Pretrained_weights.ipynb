{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Unzip file Caltech101 from the internet"
      ],
      "metadata": {
        "id": "36VumJ4E3gDU"
      }
    },
    {
      "source": [
        "!unzip /content/caltech-101.zip"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Fjrq9LEWv6Q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "Tsm41JzwwBWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Continue to extract file tar gz"
      ],
      "metadata": {
        "id": "waKyaIGI3sXA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o_R21CXl3sHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!tar -xvzf /content/caltech-101/101_ObjectCategories.tar.gz\n"
      ],
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "fWq-sh7zwOsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check device which using GPU ('cuda') or CPU"
      ],
      "metadata": {
        "id": "7MHz-54D33uK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "zhBySMzdwTR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Data Augumentation to setting the transform image and resize image to 128 for practicing. Input the mean and std of nomalize to make standard color values"
      ],
      "metadata": {
        "id": "V6OHrXOn4CIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_image = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((128, 128)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "dataset = datasets.ImageFolder(root = '/content/101_ObjectCategories', transform = transform_image)"
      ],
      "metadata": {
        "id": "dAK9eVKnwh1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split random data"
      ],
      "metadata": {
        "id": "EkkcPrhV4eyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, val_dataset = random_split(dataset, [int(0.8 * len(dataset)), len(dataset) - int(0.8 * len(dataset))])"
      ],
      "metadata": {
        "id": "7BZbgwWuxg4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset), len(val_dataset)"
      ],
      "metadata": {
        "id": "IauPrcxgxloS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create train and test loader for training"
      ],
      "metadata": {
        "id": "rHQ6sTDe4kIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size = 32, shuffle = True)\n",
        "val_loader = DataLoader(val_dataset, batch_size = 32, shuffle = False)"
      ],
      "metadata": {
        "id": "VbFEPTdhxo3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check images and labels torch size"
      ],
      "metadata": {
        "id": "SSyfEknm4qI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_loader:\n",
        "  print(images.shape, labels.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "JBZD5dAPxtBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_index = random.randint(0, len(dataset) - 1)\n",
        "random_index"
      ],
      "metadata": {
        "id": "D_dVMjfLy1d7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2wlwbW0B0q6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset.classes)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-EaOXLUqxxbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create and check classes from *dataset*"
      ],
      "metadata": {
        "id": "_RxHqukz4wuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = dataset.classes\n",
        "classes"
      ],
      "metadata": {
        "id": "5MPmi-mo0GA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print out first single image from dataset"
      ],
      "metadata": {
        "id": "vvo7SlU343rc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "single_image = dataset[50][0]\n",
        "single_image = single_image.permute(1,2,0)\n",
        "plt.imshow(single_image)\n",
        "plt.title(dataset.classes[dataset[50][1]])\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bdXhgtzmy3UU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Print out 32 images randomly"
      ],
      "metadata": {
        "id": "Nrzr3xE51xpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(nrows=4, ncols=8, figsize=(15, 5))\n",
        "axes = axes.flatten()\n",
        "for i in range(32):\n",
        "    random_index = random.randint(0, len(dataset) - 1)\n",
        "    image, label = dataset[random_index]\n",
        "\n",
        "    # Reverse normalization\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    image = image.permute(1, 2, 0).numpy()  # Convert to NumPy array\n",
        "    image = std * image + mean  # Reverse normalization\n",
        "    image = np.clip(image, 0, 1)  # Clip values to [0, 1]\n",
        "\n",
        "\n",
        "    axes[i].imshow(image)\n",
        "    axes[i].set_title(dataset.classes[label])\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3qChF39Ix4YC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create 2D Convolution neuron network define which a sequence of layers with 3 chanels (RGB) then return output of the network has been processed by all layers"
      ],
      "metadata": {
        "id": "7nOGcy855E0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self, number_output):\n",
        "    super(CNN, self).__init__()\n",
        "    self.network = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 3, padding = 'same'), # 32,128,128\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2, stride=2),   # 32, 64,64\n",
        "\n",
        "        nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, padding = 'same'),  # 32, 64,64\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2, stride=2),  # 64, 32,32\n",
        "\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features = 64 * 32 * 32, out_features = 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features = 256, out_features = 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features = 128, out_features = number_output)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "      return self.network(x)"
      ],
      "metadata": {
        "id": "hyKNg8Gly0Q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training model with train and test model then get the accuracy from scratch"
      ],
      "metadata": {
        "id": "f9Gc0z986Oq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "def train_model(model, optimizer, criterion, train_loader,val_loader, num_epochs=5):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")"
      ],
      "metadata": {
        "id": "OZm3n438ycxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(dataset.classes)\n",
        "model = CNN(num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "train_model(model, optimizer, criterion, train_loader, val_loader, num_epochs=5)"
      ],
      "metadata": {
        "id": "IWvRLfU2TrYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, val_loader):\n",
        "  with torch.no_grad():\n",
        "      model.eval()\n",
        "      total = 0\n",
        "      correct = 0\n",
        "      for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "  print(f\"accuracy : {100 * correct / total:.4f}\")\n",
        "\n",
        "test_model(model, val_loader)"
      ],
      "metadata": {
        "id": "IMQTZO_qFMTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes"
      ],
      "metadata": {
        "id": "tXbSESlUhUOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using 1 function to training and evaluation model"
      ],
      "metadata": {
        "id": "TJ0FkTmR6cFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "def train_model2(model, optimizer, criterion, train_loader,val_loader, num_epochs=1):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "        print(f\"accuracy : {100 * correct / total:.4f}\")"
      ],
      "metadata": {
        "id": "gNqKfe6fhk82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try with Pretrained model call Resnet18 to compare the accuracy"
      ],
      "metadata": {
        "id": "_uW9VpZs6lAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "train_model2(model, optimizer, criterion, train_loader, val_loader, num_epochs=5)"
      ],
      "metadata": {
        "id": "Oe3IlqCZDITg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pretrained with EfficientNet"
      ],
      "metadata": {
        "id": "vch-CMs3lbO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.efficientnet_b0(weights = 'DEFAULT')\n",
        "model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "train_model2(model, optimizer, criterion, train_loader, val_loader, num_epochs=5)"
      ],
      "metadata": {
        "id": "OANG_BrUlIf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We can see, the 2 pretrained model got better accruracy than nornal training."
      ],
      "metadata": {
        "id": "h7WamRKA64jV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Print out 25 images randomly to check the accuracy of the model"
      ],
      "metadata": {
        "id": "I-kaMIXh2-xJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UoW4CJH_7AH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(15, 10))\n",
        "axes = axes.flatten()\n",
        "for i in range(25):\n",
        "    random_index = random.randint(0, len(dataset) - 1)  # Get a random image from the dataset\n",
        "    image, label = dataset[random_index]                # Get the image and its label\n",
        "\n",
        "    # Make prediction for the image (Move image to device and get prediction)\n",
        "    image_tensor = image.unsqueeze(0).to(device)       # Add a batch dimension\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        output = model(image_tensor)\n",
        "    _, predicted = torch.max(output.data, 1)\n",
        "    predicted_class = predicted.item()                  # Get the predicted class as an integer\n",
        "\n",
        "    # Display the image with predicted and true labels\n",
        "    image = image.permute(1, 2, 0).cpu().numpy()\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    image = std * image + mean\n",
        "    image = np.clip(image, 0, 1)\n",
        "    axes[i].imshow(image)\n",
        "    axes[i].set_title(f\"pred : {classes[predicted_class]}, true : {classes[label]}\")\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GGBrqgvAzTPy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}